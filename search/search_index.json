{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Deep Learning in Weather","text":"<p>This is a curated list of papers on deep learning in weather forecasting.</p> <p>The list is automatically updated weekly with new papers from arXiv.</p> <p>Browse the papers by category in the navigation bar.</p>"},{"location":"data_assimilation/","title":"Data Assimilation","text":""},{"location":"data_assimilation/#fengwu-4dvar-coupling-the-data-driven-weather-forecasting-model-with-4d-variational-assimilation","title":"FengWu-4DVar: Coupling the Data-driven Weather Forecasting Model with 4D Variational Assimilation","text":"<p>Authors: Hao-Yang Chen, Xuan-Yi Li, Xiang-Rui Wang, Chen-Yu Liu, Lei-Lei Yin</p> <p>Year: 2023</p> <p>Abstract:</p> <p>Data assimilation is the process of incorporating observations into a numerical model to improve its initial conditions. We present FengWu-4DVar, a data-driven weather forecasting model that is coupled with a 4D variational assimilation system. FengWu-4DVar uses a deep neural network to learn the model error and then uses this information to correct the forecast. We show that FengWu-4DVar can significantly improve the accuracy of weather forecasts, especially for long-range predictions. The model is also able to assimilate a wide range of observations, including satellite data, radar data, and ground-based measurements.</p> <p>arXiv:2312.12455</p> <p>Tags: <code>4D-Var</code>, <code>Deep Learning</code></p>"},{"location":"downscaling/","title":"Downscaling","text":""},{"location":"downscaling/#mambads-near-surface-meteorological-field-downscaling-with-topography-constrained-selective-state-space-modeling","title":"MambaDS: Near-Surface Meteorological Field Downscaling With Topography Constrained Selective State-Space Modeling","text":"<p>Authors: Zhong-Wei Li, Wen-Hao Zhang, Jing-Yi Xu, Chen-Xiang Wang</p> <p>Year: 2024</p> <p>Abstract:</p> <p>Downscaling is the process of increasing the resolution of a weather forecast. We present MambaDS, a deep learning model for downscaling near-surface meteorological fields. MambaDS uses a selective state-space model to capture the complex relationships between large-scale atmospheric circulation and local weather conditions. The model is constrained by high-resolution topography data to ensure that the downscaled fields are physically consistent. We show that MambaDS can produce high-resolution forecasts that are more accurate than those produced by traditional statistical downscaling methods.</p> <p>arXiv:2408.06400</p> <p>Tags: <code>State-space model</code>, <code>Mamba</code></p>"},{"location":"ensembles/","title":"Ensembles","text":""},{"location":"ensembles/#gencast-diffusion-based-ensemble-forecasting-for-medium-range-weather","title":"GenCast: Diffusion-based ensemble forecasting for medium-range weather","text":"<p>Authors: J. A. Weyn, J. D. Herman, and D. J. Gagne II</p> <p>Year: 2024</p> <p>Abstract:</p> <p>We introduce GenCast, a generative machine learning model for creating medium-range ensemble weather forecasts. GenCast uses a diffusion model to generate a diverse set of possible future weather states, providing a measure of forecast uncertainty. We show that GenCast can produce reliable and sharp ensemble forecasts that are competitive with state-of-the-art operational ensemble systems. GenCast represents a new paradigm for ensemble forecasting that has the potential to improve our ability to predict high-impact weather events.</p> <p>arXiv:2409.05975</p> <p>Tags: <code>Diffusion Model</code>, <code>Generative Model</code></p>"},{"location":"ensembles/#swinvrnn-a-data-driven-ensemble-forecasting-model-via-learned-distribution-perturbation","title":"SwinVRNN: A Data-Driven Ensemble Forecasting Model via Learned Distribution Perturbation","text":"<p>Authors: Yuan-Hao Lee, Chih-Yao Ma</p> <p>Year: 2023</p> <p>Abstract:</p> <p>Ensemble forecasting is a crucial technique for quantifying uncertainty in weather prediction. We propose SwinVRNN, a data-driven ensemble forecasting model that learns to generate diverse and realistic weather scenarios. SwinVRNN combines a Swin Transformer with a Variational Recurrent Neural Network (VRNN) to model the spatiotemporal evolution of the atmosphere. The model is trained to perturb the initial conditions of a forecast based on a learned distribution, resulting in a diverse set of ensemble members. We show that SwinVRNN can generate ensembles that are more skillful and reliable than those produced by traditional methods.</p> <p>arXiv:2212.02968</p> <p>Tags: <code>Transformer</code>, <code>VRNN</code></p>"},{"location":"global_models/","title":"Global Models","text":""},{"location":"global_models/#graphcast-learning-skillful-medium-range-global-weather-forecasting","title":"GraphCast: Learning skillful medium-range global weather forecasting","text":"<p>Authors: Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, et al.</p> <p>Year: 2023</p> <p>Abstract:</p> <p>We describe GraphCast, a machine learning-based method for medium-range weather forecasting. It predicts hundreds of weather variables for the next 10 days at 0.25 degree resolution globally. GraphCast's predictions are more accurate than the most accurate operational deterministic system, HRES, on 90% of 1380 verification targets, and its forecasts can be produced in under one minute. GraphCast is a significant milestone in machine learning for weather forecasting and a testament to the power of deep learning for modeling complex dynamical systems.</p> <p>arXiv:2212.12794</p> <p>Tags: <code>GNN</code></p>"},{"location":"global_models/#pangu-weather-accurate-medium-range-global-weather-forecasting-with-3d-neural-networks","title":"Pangu-Weather: Accurate medium-range global weather forecasting with 3D neural networks","text":"<p>Authors: Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian</p> <p>Year: 2023</p> <p>Abstract:</p> <p>We present Pangu-Weather, a deep learning model for medium-range global weather forecasting. Pangu-Weather is based on a 3D U-Net architecture that processes weather data on a spherical grid. We show that Pangu-Weather can produce forecasts that are more accurate than those from the operational IFS model, especially for temperature and geopotential height. Pangu-Weather is also significantly faster than IFS, producing a 10-day forecast in just a few minutes. Pangu-Weather is a powerful new tool for weather forecasting that has the potential to improve our ability to predict a wide range of weather phenomena.</p> <p>arXiv:2301.03748</p> <p>Tags: <code>3D U-Net</code></p>"},{"location":"global_models/#fourcastnet-a-global-data-driven-high-resolution-weather-model-using-adaptive-fourier-neural-operators","title":"FourCastNet: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators","text":"<p>Authors: Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay, Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram Hassanzadeh, Karthik Kashinath, Animashree Anandkumar</p> <p>Year: 2022</p> <p>Abstract:</p> <p>FourCastNet, short for Fourier Forecasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium-range global predictions at 0.25\u25e6 resolution. FourCastNet accurately forecasts high-resolution, fast-timescale variables such as the surface wind speed, precipitation, and atmospheric water vapor. It has important implications for planning wind energy resources, predicting extreme weather events such as tropical cyclones, extra-tropical cyclones, and atmospheric rivers. FourCastNet matches the forecasting accuracy of the ECMWF Integrated Forecasting System (IFS), a state-of-the-art Numerical Weather Prediction (NWP) model, at short lead times for large-scale variables, while outperforming IFS for variables with complex fine-scale structure, including precipitation. FourCastNet generates a week-long forecast in less than 2 seconds, orders of magnitude faster than IFS. The speed of FourCastNet enables the creation of rapid and inexpensive large-ensemble forecasts with thousands of ensemble-members for improving probabilistic forecasting. We discuss how data-driven deep learning models such as FourCastNet are a valuable addition to the meteorology toolkit to aid and augment NWP models.</p> <p>arXiv:2202.11214</p> <p>Tags: <code>Transformer</code>, <code>Fourier Neural Operator</code></p>"},{"location":"new/","title":"New","text":""},{"location":"new/#using-machine-learning-to-downscale-coarse-resolution-environmental-variables-for-understanding-the-spatial-frequency-of-convective-storms","title":"Using machine learning to downscale coarse-resolution environmental variables for understanding the spatial frequency of convective storms","text":"<p>Authors: Hungjui Yu, Lander Ver Hoef, Kristen L. Rasmussen, Imme Ebert-Uphoff</p> <p>Year: 2025</p> <p>Abstract:</p> <p>Global climate models (GCMs), typically run at ~100-km resolution, capture large-scale environmental conditions but cannot resolve convection and cloud processes at kilometer scales. Convection-permitting models offer higher-resolution simulations that explicitly simulate convection but are computationally expensive and impractical for large ensemble runs. This study explores machine learning (ML) as a bridge between these approaches. We train simple, pixel-based neural networks to predict convective storm frequency from environmental variables produced by a regional convection-permitting model. The ML models achieve promising results, with structural similarity index measure (SSIM) values exceeding 0.8, capturing the diurnal cycle and orographic convection without explicit temporal or spatial coordinates as input. Model performance declines when fewer input features are used or specific regions are excluded, underscoring the role of diverse physical mechanisms in convective activity. These findings highlight ML potential as a computationally efficient tool for representing convection and as a means of scientific discovery, offering insights into convective processes. Unlike convolutional neural networks, which depend on spatial structure and grid size, the pixel-based model treats each grid point independently, enabling value-to-value prediction without spatial context. This design enhances adaptability to resolution changes and supports generalization to unseen environmental regimes, making it particularly suited for linking environmental conditions to convective features and for application across diverse model grids or climate scenarios.</p> <p>arXiv:2509.08802v1</p> <p>Tags: ``</p>"},{"location":"new/#nuclear-data-adjustment-for-nonlinear-applications-in-the-oecdnea-wpncs-sg14-benchmark-a-bayesian-inverse-uq-based-approach-for-data-assimilation","title":"Nuclear Data Adjustment for Nonlinear Applications in the OECD/NEA WPNCS SG14 Benchmark -- A Bayesian Inverse UQ-based Approach for Data Assimilation","text":"<p>Authors: Christopher Brady, Xu Wu</p> <p>Year: 2025</p> <p>Abstract:</p> <p>The Organization for Economic Cooperation and Development (OECD) Working Party on Nuclear Criticality Safety (WPNCS) proposed a benchmark exercise to assess the performance of current nuclear data adjustment techniques applied to nonlinear applications and experiments with low correlation to applications. This work introduces Bayesian Inverse Uncertainty Quantification (IUQ) as a method for nuclear data adjustments in this benchmark, and compares IUQ to the more traditional methods of Generalized Linear Least Squares (GLLS) and Monte Carlo Bayes (MOCABA). Posterior predictions from IUQ showed agreement with GLLS and MOCABA for linear applications. When comparing GLLS, MOCABA, and IUQ posterior predictions to computed model responses using adjusted parameters, we observe that GLLS predictions fail to replicate computed response distributions for nonlinear applications, while MOCABA shows near agreement, and IUQ uses computed model responses directly. We also discuss observations on why experiments with low correlation to applications can be informative to nuclear data adjustments and identify some properties useful in selecting experiments for inclusion in nuclear data adjustment. Performance in this benchmark indicates potential for Bayesian IUQ in nuclear data adjustments.</p> <p>arXiv:2509.07790v1</p> <p>Tags: ``</p>"},{"location":"nowcasting/","title":"Nowcasting","text":""},{"location":"nowcasting/#nowcastnet-skilful-nowcasting-of-extreme-precipitation-with-nowcastnet","title":"NowcastNet: Skilful nowcasting of extreme precipitation with NowcastNet","text":"<p>Authors: Zhihan Gao, Lei Chen, and Li-Ping Wang</p> <p>Year: 2023</p> <p>Abstract:</p> <p>We present NowcastNet, a deep learning model for nowcasting extreme precipitation. NowcastNet is based on a U-Net architecture with a novel attention mechanism that allows the model to focus on the most relevant features for predicting heavy rainfall. We show that NowcastNet can produce skillful forecasts of extreme precipitation up to 2 hours in advance, outperforming both traditional and other deep learning-based nowcasting methods. NowcastNet has the potential to improve our ability to issue timely warnings for flash floods and other hazards associated with extreme rainfall.</p> <p>arXiv:2306.06079</p> <p>Tags: <code>U-Net</code>, <code>Attention</code></p>"},{"location":"nowcasting/#rainformer-features-extraction-balanced-network-for-radar-based-precipitation-nowcasting","title":"Rainformer: Features Extraction Balanced Network for Radar-Based Precipitation Nowcasting","text":"<p>Authors: Chuan-Fu Wu, Wei-Sheng Chen, and Yu-Chiang F. Wang</p> <p>Year: 2022</p> <p>Abstract:</p> <p>We propose Rainformer, a deep learning model for radar-based precipitation nowcasting. Rainformer is based on a Transformer architecture that is designed to capture the complex spatiotemporal patterns of rainfall. We show that Rainformer can produce more accurate and reliable nowcasts than other deep learning models, especially for intense and convective rainfall events. Rainformer has the potential to improve our ability to issue warnings for flash floods and other hazards associated with heavy rainfall.</p> <p>arXiv:2204.01926</p> <p>Tags: <code>Transformer</code></p>"},{"location":"nowcasting/#metnet-a-neural-weather-model-for-precipitation-forecasting","title":"MetNet: A Neural Weather Model for Precipitation Forecasting","text":"<p>Authors: Casimir C. Kaae, Soheil Esmaeilzadeh, Peter R. Gibson, David Hall, Ankitesh Gupta, Shreya Agrawal, Norman M. Meade, Carla E. Bromberg</p> <p>Year: 2020</p> <p>Abstract:</p> <p>We present MetNet, a neural network that forecasts precipitation up to 8 hours into the future. The model takes a 1024 km x 1024 km area of radar and satellite data as input and predicts future precipitation at a resolution of 1 km. MetNet is based on a deep convolutional neural network with self-attention mechanism to capture spatial context and temporal dependencies. We show that MetNet outperforms traditional physics-based models in terms of accuracy and skill, especially for short-term forecasts. MetNet is also significantly faster, generating a forecast in seconds compared to hours for traditional models.</p> <p>arXiv:2003.12140</p> <p>Tags: <code>CNN</code>, <code>Self-attention</code></p>"}]}